{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fffca616",
   "metadata": {},
   "source": [
    "## ML Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6205f2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import opensmile\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import torchaudio.functional as F\n",
    "import torchaudio.transforms as T\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, precision_recall_fscore_support, confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde7ee32",
   "metadata": {},
   "source": [
    "## Featrue Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c060b453",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_rate = 16000\n",
    "n_fft = int(0.025 * sampling_rate)\n",
    "win_length = int(0.025 * sampling_rate)\n",
    "hop_length = int(0.01 * sampling_rate)\n",
    "n_mels = 96\n",
    "n_mfcc = 13\n",
    "melkwargs={\n",
    "      'n_fft': n_fft,\n",
    "      'n_mels': n_mels,\n",
    "      'hop_length': hop_length,\n",
    "    }\n",
    "dirs = \"../dataset/feature/npy\"\n",
    "fnames = os.listdir(dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bbd8f93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "smile = opensmile.Smile(\n",
    "    feature_set=opensmile.FeatureSet.eGeMAPSv02,\n",
    "    feature_level=opensmile.FeatureLevel.Functionals,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d5159fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████| 488/488 [00:26<00:00, 18.73it/s]\n"
     ]
    }
   ],
   "source": [
    "rms_dict = {}\n",
    "pitch_dict = {}\n",
    "mfccs_dict = {}\n",
    "egemaps_dict = {}\n",
    "for fname in tqdm(fnames):\n",
    "    _id = fname.replace(\".npy\",\"\")\n",
    "    y = np.load(os.path.join(dirs, fname))\n",
    "    mfcc_emb = librosa.feature.mfcc(\n",
    "        y = y.squeeze(0), \n",
    "        n_mfcc =n_mfcc,\n",
    "        sr=sampling_rate, \n",
    "        n_fft=n_fft, \n",
    "        hop_length=hop_length, \n",
    "        n_mels=n_mels,\n",
    "    )\n",
    "    egemaps = smile.process_signal(signal=y,sampling_rate=16000)\n",
    "    egemaps = list(egemaps.to_numpy().squeeze(0))\n",
    "    mean_mfcc = list(mfcc_emb.mean(axis=1)) # temporal pooling\n",
    "    std_mfcc = list(mfcc_emb.std(axis=1)) # temporal pooling\n",
    "    pitchs = F.detect_pitch_frequency(torch.from_numpy(y.squeeze(0)), sampling_rate).numpy()\n",
    "    pitch = np.array([i for i in pitchs if i < 1000])\n",
    "    mean_pitch = pitch.mean()\n",
    "    std_pitch = pitch.std()\n",
    "    rms = librosa.feature.rms(y=y.squeeze(0))\n",
    "    mean_rms = rms.mean()\n",
    "    std_rms = rms.std()\n",
    "    rms_dict[_id] = rms\n",
    "    pitch_dict[_id] = pitch\n",
    "    mfccs_dict[_id] = mfcc_emb\n",
    "    egemaps_dict[_id] = egemaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37f0fadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(egemaps_dict, \"../dataset/feature/handcraft/egemaps.pt\")\n",
    "torch.save(rms_dict, \"../dataset/feature/handcraft/energy.pt\")\n",
    "torch.save(pitch_dict, \"../dataset/feature/handcraft/pitch.pt\")\n",
    "torch.save(mfccs_dict, \"../dataset/feature/handcraft/mfccs.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0ef8bad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.48214285714285715 0.3897058823529412\n",
      "0.5932203389830508 0.5568627450980392\n",
      "0.55 0.48541666666666666\n",
      "0.4393939393939394 0.41666666666666663\n",
      "0.375 0.38257575757575757\n",
      "0.5223880597014925 0.5133053221288516\n",
      "0.7741935483870968 0.7633928571428572\n",
      "0.34285714285714286 0.3464052287581699\n"
     ]
    }
   ],
   "source": [
    "fold_case = ['M1','M2','M3','M4','F5','F6','F7','F8']\n",
    "all_samples = []\n",
    "all_labels = []\n",
    "all_preds = []\n",
    "label_dist = {}\n",
    "for fold in fold_case:\n",
    "    df_tr = pd.read_csv(f\"../dataset/split/{fold}_train.csv\",index_col=0)\n",
    "    df_va = pd.read_csv(f\"../dataset/split/{fold}_valid.csv\",index_col=0)\n",
    "    df_train = pd.concat([df_tr, df_va])\n",
    "    df_eval = pd.read_csv(f\"../dataset/split/{fold}_eval.csv\",index_col=0)\n",
    "    label_dist[fold] = {\"tr\":df_train.sum(), \"te\":df_eval.sum()}\n",
    "    X_train = np.stack([egemaps_dict[idx] for idx in df_train.index])\n",
    "    y_train = np.stack(list(df_train.idxmax(axis=1)))\n",
    "    X_test = np.stack([egemaps_dict[idx] for idx in df_eval.index])\n",
    "    y_test = np.stack(list(df_eval.idxmax(axis=1)))\n",
    "    \n",
    "    classifier = make_pipeline(StandardScaler(),LogisticRegression(random_state=42, max_iter=3000))\n",
    "    classifier.fit(X_train, y_train)\n",
    "    predictions = classifier.predict(X_test)\n",
    "    WA = accuracy_score(y_test, predictions)\n",
    "    UA = balanced_accuracy_score(y_test, predictions)\n",
    "    print(WA, UA)\n",
    "    # WA, UA evaluation\n",
    "    all_labels.extend(list(y_test))\n",
    "    all_preds.extend(list(predictions))\n",
    "    all_samples.extend(list(df_eval.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f18e6e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(index=all_samples)\n",
    "results['all_preds'] = all_preds\n",
    "results['all_labels'] = all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aea96def",
   "metadata": {},
   "outputs": [],
   "source": [
    "# weighted_acc & un-weighted acc\n",
    "WA = accuracy_score(results['all_labels'], results['all_preds'])\n",
    "UA = balanced_accuracy_score(results['all_labels'], results['all_preds'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1dbc6ee1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5102459016393442, 0.5063647154374167)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WA, UA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a50eed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
